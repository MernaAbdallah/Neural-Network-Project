{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRhdgVIXfneF"
      },
      "source": [
        "#Used Libiraies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV1nRMaAdcR8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import imghdr\n",
        "import random\n",
        "import pickle\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense,GlobalMaxPool2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preparation"
      ],
      "metadata": {
        "id": "MFJUcvmTTuFs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNpoV_rchgBr"
      },
      "source": [
        "Import The dataset from Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idfVA3MvhesC",
        "outputId": "39ce752b-9f39-46f1-95fe-09d8e5053b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "test_path='/content/drive/MyDrive/test'\n",
        "train_path='/content/drive/MyDrive/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6grFF_vlOILQ",
        "outputId": "9b67ccf0-85be-4ab1-f284-085e8ee71977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw76IPlShpiX"
      },
      "source": [
        "Apply PreProcessing on Training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIVmh_Rho8-t",
        "outputId": "a3a1d300-68b7-47a9-d034-02fd60795e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7920 images belonging to 5 classes.\n",
            "Found 1980 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "def Train_data_preprocessing_(path):\n",
        "    \"\"\"\n",
        "    ImageDataGenerator is a class in keras.preprocessing that generates batches of images data\n",
        "    with real-time data augmentation.\n",
        "\n",
        "    Note : \"real-time\" indicates that these transformations are applied dynamically and on the fly,\n",
        "    just before each training batch is fed into the neural network to enhance the model's ability to generalize to new, unseen data.\n",
        "\n",
        "    This function take a path argument and returns two datasets: train_dataset and Validation_dataset\n",
        "    The function applies the train test split on the data after the preprocessing\n",
        "    class_mode: the type of classification problem.\n",
        "    \"\"\"\n",
        "    image_generator = ImageDataGenerator(\n",
        "        rescale=1 / 255,\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2, )\n",
        "\n",
        "    # Train & Test Split\n",
        "    train_dataset = image_generator.flow_from_directory(batch_size=32,directory=path,shuffle=True,target_size=(150, 150),\n",
        "                                                        subset=\"training\",class_mode='categorical')\n",
        "\n",
        "    validation_dataset = image_generator.flow_from_directory(batch_size=32, directory=path,shuffle=True, target_size=(150, 150),\n",
        "                                                             subset=\"validation\",class_mode='categorical')\n",
        "    return train_dataset, validation_dataset\n",
        "\n",
        "train , validation = Train_data_preprocessing_(train_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hzf1MvxNgHJ"
      },
      "source": [
        "Apply Preprocessing on Testing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tyNzg4QNvms",
        "outputId": "e8c015d0-2152-4c42-a3fd-883c03fac1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading test images\n",
            "Done.\n",
            "Total test images: 100\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "def preprocessed_test_data(path):\n",
        "    \"\"\"\n",
        "    This function processes test images in (test_path). It reads each image,\n",
        "    converts the color space from BGR to RGB, resizes the image to (100, 100),and normalizes the pixel values.\n",
        "    The processed test images and their names are then stored in the data and image_name lists,\n",
        "    which are returned at the end of the function.\n",
        "\n",
        "    Note  : we stored the image name because we will use it in the final csv file\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    image_name = []\n",
        "    print(\"loading test images\")\n",
        "    \"\"\"\n",
        "     This loop Iterates through the test classes from the given path and read each image using openCV\n",
        "    \"\"\"\n",
        "    for img in os.listdir(path):\n",
        "        image_name.append(img)\n",
        "        test_img_array = cv2.imread(os.path.join(path, img))\n",
        "        if test_img_array is not None:\n",
        "          # BGR to RGB\n",
        "          test_img_array = cv2.cvtColor(test_img_array, cv2.COLOR_BGR2RGB)\n",
        "          # Resize\n",
        "          test_img_array = cv2.resize(test_img_array, (150, 150))\n",
        "          # Normalization\n",
        "          test_img_array = test_img_array.astype(np.float32)\n",
        "          test_img_array=test_img_array/255\n",
        "\n",
        "          # test_img_array = (test_img_array - np.min(test_img_array)) / (np.max(test_img_array) - np.min(test_img_array))*255\n",
        "          ###############################\n",
        "          data.append(test_img_array)\n",
        "        else :\n",
        "          print(f\"Failed to read image: {os.path.join(path, img)}\")\n",
        "\n",
        "    print(\"Done.\")\n",
        "    print(\"Total test images:\", len(data))\n",
        "    print(\"------------------------------\")\n",
        "    return data, image_name\n",
        "\n",
        "test , images_names= preprocessed_test_data(test_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Models"
      ],
      "metadata": {
        "id": "4FOdKpzgV7wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Model"
      ],
      "metadata": {
        "id": "wNbxW5N4gy-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model_1(train_data, val_data, epochs):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(BatchNormalization())\n",
        "    #model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(BatchNormalization())\n",
        "    #model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(BatchNormalization())\n",
        "    #model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(BatchNormalization())\n",
        "    #model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3)))\n",
        "    model.add(GlobalMaxPool2D())\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "\n",
        "    #model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "\n",
        "    # Define model checkpoint callback\n",
        "    model_checkpoint = ModelCheckpoint('model_1.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    print(\"Start training...\")\n",
        "    model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=[early_stopping, model_checkpoint])\n",
        "    print(\"Finished training...\")\n",
        "\n",
        "    return model\n",
        "\n",
        "cnn_model_1_1 = cnn_model_1(train, validation, 100)"
      ],
      "metadata": {
        "id": "MWmQmki9pgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seconed Model"
      ],
      "metadata": {
        "id": "nfC92X2Jg2vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model_2(train_data, val_data, epochs):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(12, (5, 5), activation='relu', kernel_initializer='he_uniform', input_shape=(150, 150, 3)))\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(500, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(400, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(300, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(200, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(50, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "    # Use a learning rate scheduler\n",
        "    def lr_schedule(epoch):\n",
        "        lr = 0.001\n",
        "        if epoch > 50:\n",
        "            lr *= 0.5\n",
        "        if epoch > 100:\n",
        "            lr *= 0.5\n",
        "        return lr\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Define model checkpoint callback\n",
        "    model_checkpoint = ModelCheckpoint('model_2.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    # Define learning rate scheduler callback\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    print(\"Start training...\")\n",
        "    model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=[early_stopping, model_checkpoint, lr_scheduler])\n",
        "    print(\"Finished training...\")\n",
        "\n",
        "    return model\n",
        "\n",
        "cnn_model_2_2 = cnn_model_2(train, validation, 300)"
      ],
      "metadata": {
        "id": "rLeDzVltg4r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlexNet Model"
      ],
      "metadata": {
        "id": "2tA13pJxoJeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_alexnet(input_shape=(150, 150, 3), num_classes=5):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Block 1\n",
        "    model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Convolutional Block 3\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1000, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_alexnet(model, train_data, test_data, epochs=100):\n",
        "    # Define early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Define model checkpoint callback to save the best weights\n",
        "    model_checkpoint = ModelCheckpoint('alexnet_best22.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "    # Training\n",
        "    print(\"Start training...\")\n",
        "    model.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[early_stopping, model_checkpoint], verbose=1)\n",
        "    print(\"Finished training...\")\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (150, 150, 3)\n",
        "num_classes = 5\n",
        "\n",
        "# Build and train the model\n",
        "alexnet_model = build_alexnet(input_shape, num_classes)\n",
        "trained_model = train_alexnet(alexnet_model, train, test, epochs=100)"
      ],
      "metadata": {
        "id": "Tsh65I8poMIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw63liiQDa9D"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSauUbHFCVUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346f97fa-bef9-4b51-853a-66daed82db0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "image: 1\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1: 11.46%, 2: 44.53%, 3: 12.81%, 4: 30.57%, 5: 0.63%\n",
            "image: 2\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 10.68%, 2: 42.36%, 3: 20.63%, 4: 25.73%, 5: 0.60%\n",
            "image: 3\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 7.72%, 2: 7.65%, 3: 77.64%, 4: 1.19%, 5: 5.80%\n",
            "image: 4\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 10.88%, 2: 17.76%, 3: 62.84%, 4: 4.96%, 5: 3.56%\n",
            "image: 5\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 3.37%, 2: 5.95%, 3: 87.38%, 4: 0.41%, 5: 2.89%\n",
            "image: 6\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1: 30.66%, 2: 6.25%, 3: 14.85%, 4: 4.23%, 5: 44.00%\n",
            "image: 7\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 6.22%, 2: 30.47%, 3: 0.51%, 4: 62.79%, 5: 0.02%\n",
            "image: 8\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 4.44%, 2: 7.71%, 3: 84.63%, 4: 0.97%, 5: 2.25%\n",
            "image: 9\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 7.11%, 2: 50.36%, 3: 4.57%, 4: 37.83%, 5: 0.13%\n",
            "image: 10\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 14.58%, 2: 33.52%, 3: 31.72%, 4: 18.06%, 5: 2.11%\n",
            "image: 11\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 7.24%, 2: 0.68%, 3: 4.02%, 4: 0.11%, 5: 87.96%\n",
            "image: 12\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 10.27%, 2: 41.55%, 3: 21.52%, 4: 26.24%, 5: 0.42%\n",
            "image: 13\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 32.07%, 2: 7.53%, 3: 20.39%, 4: 5.35%, 5: 34.66%\n",
            "image: 14\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1: 16.67%, 2: 17.50%, 3: 53.53%, 4: 6.73%, 5: 5.58%\n",
            "image: 15\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 27.23%, 2: 6.84%, 3: 28.15%, 4: 3.06%, 5: 34.71%\n",
            "image: 16\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 4.73%, 2: 7.46%, 3: 84.11%, 4: 0.91%, 5: 2.79%\n",
            "image: 17\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1: 25.53%, 2: 3.74%, 3: 12.08%, 4: 2.11%, 5: 56.54%\n",
            "image: 18\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 8.93%, 2: 46.23%, 3: 12.27%, 4: 32.38%, 5: 0.20%\n",
            "image: 19\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 12.56%, 2: 32.07%, 3: 40.19%, 4: 13.20%, 5: 1.98%\n",
            "image: 20\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 13.50%, 2: 1.54%, 3: 5.47%, 4: 0.54%, 5: 78.96%\n",
            "image: 21\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 2.73%, 2: 0.08%, 3: 0.68%, 4: 0.01%, 5: 96.50%\n",
            "image: 22\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 27.06%, 2: 2.82%, 3: 10.56%, 4: 2.30%, 5: 57.25%\n",
            "image: 23\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 1.24%, 2: 37.91%, 3: 0.14%, 4: 60.71%, 5: 0.00%\n",
            "image: 24\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 10.45%, 2: 24.63%, 3: 54.72%, 4: 8.18%, 5: 2.01%\n",
            "image: 25\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 11.63%, 2: 39.47%, 3: 25.23%, 4: 22.71%, 5: 0.96%\n",
            "image: 26\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 12.79%, 2: 35.97%, 3: 30.15%, 4: 19.65%, 5: 1.45%\n",
            "image: 27\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 4.04%, 2: 0.00%, 3: 0.10%, 4: 0.00%, 5: 95.85%\n",
            "image: 28\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 5.28%, 2: 0.05%, 3: 0.37%, 4: 0.02%, 5: 94.28%\n",
            "image: 29\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 12.02%, 2: 42.18%, 3: 25.01%, 4: 19.72%, 5: 1.07%\n",
            "image: 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 2.88%, 2: 0.04%, 3: 0.53%, 4: 0.01%, 5: 96.55%\n",
            "image: 31\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1: 24.54%, 2: 3.01%, 3: 10.35%, 4: 1.89%, 5: 60.20%\n",
            "image: 32\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 1.06%, 2: 0.00%, 3: 0.06%, 4: 0.00%, 5: 98.88%\n",
            "image: 33\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 18.63%, 2: 2.37%, 3: 10.61%, 4: 0.91%, 5: 67.47%\n",
            "image: 34\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1: 13.34%, 2: 33.88%, 3: 32.54%, 4: 18.48%, 5: 1.76%\n",
            "image: 35\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 5.08%, 2: 11.16%, 3: 79.51%, 4: 1.15%, 5: 3.10%\n",
            "image: 36\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 10.42%, 2: 23.56%, 3: 56.55%, 4: 7.18%, 5: 2.29%\n",
            "image: 37\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 3.67%, 2: 40.98%, 3: 1.22%, 4: 54.12%, 5: 0.01%\n",
            "image: 38\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 8.27%, 2: 0.03%, 3: 0.64%, 4: 0.03%, 5: 91.03%\n",
            "image: 39\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 58.57%, 2: 5.05%, 3: 3.68%, 4: 13.37%, 5: 19.33%\n",
            "image: 40\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 6.38%, 2: 43.62%, 3: 5.15%, 4: 44.80%, 5: 0.05%\n",
            "image: 41\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 8.23%, 2: 46.51%, 3: 8.16%, 4: 36.96%, 5: 0.14%\n",
            "image: 42\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 7.53%, 2: 0.03%, 3: 0.48%, 4: 0.03%, 5: 91.93%\n",
            "image: 43\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 4.17%, 2: 0.01%, 3: 0.19%, 4: 0.01%, 5: 95.62%\n",
            "image: 44\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1: 11.23%, 2: 39.99%, 3: 24.07%, 4: 23.92%, 5: 0.79%\n",
            "image: 45\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 1.83%, 2: 0.01%, 3: 0.12%, 4: 0.00%, 5: 98.05%\n",
            "image: 46\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 20.82%, 2: 3.04%, 3: 12.56%, 4: 1.24%, 5: 62.35%\n",
            "image: 47\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 10.74%, 2: 0.62%, 3: 3.37%, 4: 0.16%, 5: 85.11%\n",
            "image: 48\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 13.55%, 2: 0.17%, 3: 1.43%, 4: 0.14%, 5: 84.71%\n",
            "image: 49\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 13.75%, 2: 13.20%, 3: 61.26%, 4: 3.44%, 5: 8.35%\n",
            "image: 50\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 6.82%, 2: 53.58%, 3: 6.79%, 4: 32.68%, 5: 0.13%\n",
            "image: 51\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 9.06%, 2: 17.79%, 3: 67.63%, 4: 3.56%, 5: 1.96%\n",
            "image: 52\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 1.31%, 2: 3.44%, 3: 92.78%, 4: 0.06%, 5: 2.41%\n",
            "image: 53\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 14.23%, 2: 36.66%, 3: 8.96%, 4: 39.74%, 5: 0.41%\n",
            "image: 54\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1: 11.04%, 2: 42.44%, 3: 20.32%, 4: 25.52%, 5: 0.68%\n",
            "image: 55\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 13.31%, 2: 1.91%, 3: 8.08%, 4: 0.35%, 5: 76.35%\n",
            "image: 56\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 9.07%, 2: 2.17%, 3: 10.40%, 4: 0.28%, 5: 78.09%\n",
            "image: 57\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1: 12.68%, 2: 36.60%, 3: 28.87%, 4: 20.52%, 5: 1.33%\n",
            "image: 58\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1: 22.96%, 2: 3.60%, 3: 14.12%, 4: 1.71%, 5: 57.61%\n",
            "image: 59\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 2.58%, 2: 0.07%, 3: 0.74%, 4: 0.01%, 5: 96.61%\n",
            "image: 60\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 31.97%, 2: 9.44%, 3: 22.74%, 4: 6.01%, 5: 29.84%\n",
            "image: 61\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 13.99%, 2: 33.17%, 3: 33.34%, 4: 17.66%, 5: 1.85%\n",
            "image: 62\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1: 2.04%, 2: 40.11%, 3: 0.40%, 4: 57.45%, 5: 0.00%\n",
            "image: 63\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 14.19%, 2: 0.04%, 3: 0.44%, 4: 0.05%, 5: 85.29%\n",
            "image: 64\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1: 10.71%, 2: 33.23%, 3: 2.82%, 4: 53.10%, 5: 0.14%\n",
            "image: 65\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1: 14.25%, 2: 34.42%, 3: 29.94%, 4: 19.56%, 5: 1.83%\n",
            "image: 66\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 18.35%, 2: 0.89%, 3: 4.48%, 4: 0.62%, 5: 75.66%\n",
            "image: 67\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1: 11.57%, 2: 39.87%, 3: 23.96%, 4: 23.78%, 5: 0.82%\n",
            "image: 68\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1: 18.67%, 2: 28.99%, 3: 33.74%, 4: 15.16%, 5: 3.44%\n",
            "image: 69\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 29.24%, 2: 24.35%, 3: 15.91%, 4: 25.30%, 5: 5.19%\n",
            "image: 70\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1: 10.95%, 2: 4.66%, 3: 66.58%, 4: 0.56%, 5: 17.25%\n",
            "image: 71\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 20.68%, 2: 7.13%, 3: 46.04%, 4: 1.99%, 5: 24.17%\n",
            "image: 72\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1: 6.30%, 2: 54.03%, 3: 9.87%, 4: 29.63%, 5: 0.18%\n",
            "image: 73\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 7.43%, 2: 0.17%, 3: 1.19%, 4: 0.06%, 5: 91.15%\n",
            "image: 74\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1: 9.21%, 2: 45.83%, 3: 19.43%, 4: 25.14%, 5: 0.39%\n",
            "image: 75\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1: 18.16%, 2: 0.97%, 3: 2.69%, 4: 0.29%, 5: 77.90%\n",
            "image: 76\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1: 15.93%, 2: 0.20%, 3: 1.74%, 4: 0.21%, 5: 81.92%\n",
            "image: 77\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 12.22%, 2: 34.60%, 3: 34.13%, 4: 17.60%, 5: 1.44%\n",
            "image: 78\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1: 3.05%, 2: 42.58%, 3: 0.64%, 4: 53.73%, 5: 0.00%\n",
            "image: 79\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1: 29.88%, 2: 11.01%, 3: 16.48%, 4: 5.44%, 5: 37.18%\n",
            "image: 80\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 0.42%, 2: 1.46%, 3: 97.22%, 4: 0.01%, 5: 0.89%\n",
            "image: 81\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1: 6.58%, 2: 9.79%, 3: 78.52%, 4: 1.61%, 5: 3.51%\n",
            "image: 82\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1: 0.75%, 2: 2.49%, 3: 94.99%, 4: 0.03%, 5: 1.73%\n",
            "image: 83\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1: 2.10%, 2: 27.36%, 3: 0.12%, 4: 70.43%, 5: 0.00%\n",
            "image: 84\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1: 15.97%, 2: 32.60%, 3: 29.55%, 4: 19.85%, 5: 2.02%\n",
            "image: 85\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1: 33.47%, 2: 8.51%, 3: 18.08%, 4: 7.38%, 5: 32.56%\n",
            "image: 86\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1: 17.81%, 2: 2.69%, 3: 11.33%, 4: 1.16%, 5: 67.01%\n",
            "image: 87\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1: 6.66%, 2: 8.23%, 3: 81.40%, 4: 1.63%, 5: 2.08%\n",
            "image: 88\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1: 2.91%, 2: 6.13%, 3: 88.56%, 4: 0.53%, 5: 1.86%\n",
            "image: 89\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 12.38%, 2: 36.77%, 3: 28.67%, 4: 20.98%, 5: 1.20%\n",
            "image: 90\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1: 7.45%, 2: 0.65%, 3: 3.27%, 4: 0.08%, 5: 88.55%\n",
            "image: 91\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1: 19.53%, 2: 0.63%, 3: 3.70%, 4: 0.50%, 5: 75.64%\n",
            "image: 92\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1: 1.57%, 2: 43.59%, 3: 0.13%, 4: 54.71%, 5: 0.00%\n",
            "image: 93\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1: 5.45%, 2: 9.96%, 3: 79.89%, 4: 1.09%, 5: 3.61%\n",
            "image: 94\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1: 0.64%, 2: 23.46%, 3: 0.02%, 4: 75.88%, 5: 0.00%\n",
            "image: 95\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1: 2.15%, 2: 39.53%, 3: 0.61%, 4: 57.71%, 5: 0.00%\n",
            "image: 96\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 4.65%, 2: 0.05%, 3: 0.50%, 4: 0.02%, 5: 94.78%\n",
            "image: 97\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1: 14.46%, 2: 36.95%, 3: 25.38%, 4: 21.72%, 5: 1.49%\n",
            "image: 98\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1: 9.05%, 2: 41.41%, 3: 8.42%, 4: 40.95%, 5: 0.18%\n",
            "image: 99\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1: 10.09%, 2: 48.05%, 3: 13.47%, 4: 28.02%, 5: 0.37%\n",
            "image: 100\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1: 14.31%, 2: 34.11%, 3: 30.99%, 4: 18.72%, 5: 1.88%\n"
          ]
        }
      ],
      "source": [
        "def test_model(model, test_data):\n",
        "    c = 1\n",
        "    labels = []\n",
        "    print(\"Predictions:\")\n",
        "    for img in test_data:\n",
        "        print(\"image:\", c)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        prediction = model.predict(img)\n",
        "        # Convert the prediction array to a list for formatting\n",
        "        prediction_list = prediction.squeeze().tolist()\n",
        "\n",
        "        print(f'1: {prediction_list[0] * 100:.2f}%, 2: {prediction_list[1] * 100:.2f}%, '\n",
        "              f'3: {prediction_list[2] * 100:.2f}%, 4: {prediction_list[3] * 100:.2f}%, '\n",
        "              f'5: {prediction_list[4] * 100:.2f}%')\n",
        "\n",
        "        labels.append(prediction.argmax())\n",
        "\n",
        "        c += 1\n",
        "    return labels\n",
        "\n",
        "model = load_model('exampel.h5')\n",
        "test_data_labels  = test_model(model , test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxOH9bDyX3kx"
      },
      "source": [
        "Converting to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMtigM7mX5tF"
      },
      "outputs": [],
      "source": [
        "def generate_csv(classified_images):\n",
        "    fields = ['image_id', 'label']\n",
        "    with open('try', 'w') as f:\n",
        "        write = csv.writer(f)\n",
        "        write.writerow(fields)\n",
        "        write.writerows(classified_images)\n",
        "\n",
        "Classified_Images = list(zip(images_names, test_data_labels))\n",
        "generate_csv(Classified_Images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qzJ5GkmYETr"
      },
      "source": [
        "Apply required format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0jUrEBJYJ9y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "25bcae19-9903-4984-cd89-b0458531d0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-7b897b952d2e>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  file_csv['image_id'] = file_csv['image_id'].str.replace('.jpeg', '')\n",
            "<ipython-input-55-7b897b952d2e>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  file_csv['image_id'] = file_csv['image_id'].str.replace('.png', '')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id  label\n",
              "0      2044      2\n",
              "1      1455      2\n",
              "2      1222      3\n",
              "3      1090      3\n",
              "4      1073      3\n",
              "..      ...    ...\n",
              "95     1593      5\n",
              "96      710      2\n",
              "97     2727      2\n",
              "98     2279      2\n",
              "99     1423      2\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ded07959-1095-4842-bba0-51be5641ade8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2044</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1455</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1222</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1090</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1073</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1593</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>710</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2727</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2279</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1423</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ded07959-1095-4842-bba0-51be5641ade8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ded07959-1095-4842-bba0-51be5641ade8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ded07959-1095-4842-bba0-51be5641ade8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbe3e14e-6d83-4f11-b83a-fb7f623d2319\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbe3e14e-6d83-4f11-b83a-fb7f623d2319')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbe3e14e-6d83-4f11-b83a-fb7f623d2319 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "def formating (path):\n",
        "  # Read the CSV file into a DataFrame\n",
        "  file_csv = pd.read_csv(path)\n",
        "\n",
        "  # Assuming the second column is named 'column_name', replace the values\n",
        "  file_csv['label'] = file_csv['label'] + 1\n",
        "  file_csv['image_id'] = file_csv['image_id'].str.replace('.jpeg', '')\n",
        "  file_csv['image_id'] = file_csv['image_id'].str.replace('.png', '')\n",
        "\n",
        "\n",
        "\n",
        "  # Save the modified DataFrame back to the CSV file\n",
        "  file_csv.to_csv(path, index=False)\n",
        "  return file_csv\n",
        "# call the function and give it te path\n",
        "formating('/content/try')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6qVoqtJEYT9"
      },
      "source": [
        "Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3Ysm8mqCX22"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "#This function takes an input tensor x (image) and applies a convolutional layer to extract patch embeddings.\n",
        "#The convolutional layer uses a kernel size specified by patch_size, and the resulting tensor is reshaped to flatten the spatial dimensions\n",
        "def patch_embedding(x, patch_size=8, emb_size=128):\n",
        "    x = layers.Reshape((-1, patch_size * patch_size * 3))(x)\n",
        "    x = layers.Dense(emb_size)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#This function implements the attention mechanism using dense layers for queries, keys, and values.\n",
        "#The MultiHeadAttention layer processes the queries, keys, and values in parallel across multiple heads.\n",
        "def attention(x, dim, n_heads, dropout=0.):\n",
        "    q = layers.Dense(dim)(x) #Linear Transformed\n",
        "    k = layers.Dense(dim)(x)\n",
        "    v = layers.Dense(dim)(x)\n",
        "    attn_output = layers.MultiHeadAttention(num_heads=n_heads, key_dim=dim, dropout=dropout)(q, k, v)\n",
        "    return attn_output\n",
        "\n",
        "\n",
        "#Implements a feed-forward layer with a ReLU activation function and dropout for regularization.\n",
        "def feed_forward(x, dim, hidden_dim, dropout=0.): #transform attention weighted vectors\n",
        "    x = layers.Dense(hidden_dim, activation='relu')(x)\n",
        "    x = layers.Dropout(dropout)(x) #to avoid over fitting\n",
        "    x = layers.Dense(dim)(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "#Adds a residual connection by adding the original input tensor x to the output of a given function fn(x).\n",
        "def residual_add(x, fn): #add inputs before and after the function and add '(+)' them\n",
        "    res = x\n",
        "    x = fn(x)\n",
        "    x += res\n",
        "    return x\n",
        "\n",
        "\n",
        "#Combines the attention mechanism and feed-forward layer using a residual connection and layer normalization.\n",
        "def transformer_block(x, dim, n_heads, dropout=0.1):\n",
        "    x = residual_add(x, lambda x: layers.LayerNormalization()(attention(x, dim, n_heads, dropout))) #Layer normalization not batch as we use sequences\n",
        "    x = residual_add(x, lambda x: layers.LayerNormalization()(feed_forward(x, dim, dim, dropout)))\n",
        "    return x\n",
        "\n",
        "#The overall ViT model architecture, including patch embedding, positional encoding, transformer blocks, and output layer.\n",
        "def vit_model(img_size=150, patch_size=3, emb_dim=32, n_layers=6, n_heads=2, out_dim=5, dropout=0.1):\n",
        "    num_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
        "    x = patch_embedding(inputs, patch_size, emb_dim)\n",
        "\n",
        "    cls_token = tf.Variable(tf.random.normal((1, 1, emb_dim)))\n",
        "    pos_embedding = tf.Variable(tf.random.normal((1, num_patches + 1, emb_dim)))\n",
        "    cls_tokens = tf.tile(cls_token, [tf.shape(x)[0], 1, 1])\n",
        "    x = tf.concat([cls_tokens, x], axis=1)\n",
        "    x += pos_embedding[:, :(num_patches + 1)]\n",
        "\n",
        "    for _ in range(n_layers):\n",
        "        x = transformer_block(x, emb_dim, n_heads, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(out_dim, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = vit_model(img_size=150, patch_size=3, emb_dim=32, n_layers=6, n_heads=2, out_dim=5, dropout=0.1)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# Train the model\n",
        "model_f = model.fit(train,\n",
        "                    validation_data=validation,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stopping])\n",
        "# Access training and validation loss\n",
        "training_loss = model_f.history['loss']\n",
        "validation_loss = model_f.history['val_loss']\n",
        "\n",
        "# Plot training and validation loss\n",
        "epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, training_loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, validation_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('training_validation_loss_plot.png')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"transformer.h5\")\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fhnnWvONttr"
      },
      "outputs": [],
      "source": [
        "# Testing the model\n",
        "tansformer_model = load_model('transformer.h5')\n",
        "transformer_test_D_L  = test_model(tansformer_model , test)\n",
        "\n",
        "transformer_Classified_Images = list(zip(images_names, transformer_test_D_L))\n",
        "generate_csv(transformer_Classified_Images)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formating('try')"
      ],
      "metadata": {
        "id": "ytopnJ1plGbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}